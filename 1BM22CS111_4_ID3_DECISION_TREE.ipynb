{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvZx2vu2D8XAvQkUbdHHC9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemaP-0303/ML_LAB/blob/main/1BM22CS111_4_ID3_DECISION_TREE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(y):\n",
        "    # Convert string labels to numerical representation (e.g., 0 and 1)\n",
        "    unique_labels = np.unique(y)\n",
        "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
        "    numerical_y = np.array([label_mapping[label] for label in y])\n",
        "\n",
        "    counts = np.bincount(numerical_y)  # Now use numerical_y for bincount\n",
        "    probabilities = counts / len(numerical_y)\n",
        "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(X, y, feature_index):\n",
        "    total_entropy = entropy(y)\n",
        "    values, counts = np.unique(X[:, feature_index], return_counts=True)\n",
        "    weighted_entropy = sum((counts[i] / sum(counts)) * entropy(y[X[:, feature_index] == values[i]]) for i in range(len(values)))\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# Function to build decision tree\n",
        "def id3(X, y, features):\n",
        "    if len(set(y)) == 1:\n",
        "        return y[0]\n",
        "    if len(features) == 0:\n",
        "        return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "    gains = [information_gain(X, y, i) for i in range(len(features))]\n",
        "    best_feature = np.argmax(gains)\n",
        "\n",
        "    tree = {features[best_feature]: {}}\n",
        "    values = np.unique(X[:, best_feature])\n",
        "    for value in values:\n",
        "        sub_X = X[X[:, best_feature] == value]\n",
        "        sub_y = y[X[:, best_feature] == value]\n",
        "        sub_features = features[:best_feature] + features[best_feature+1:]\n",
        "        tree[features[best_feature]][value] = id3(sub_X, sub_y, sub_features)\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Function to print decision tree\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for key, value in tree.items():\n",
        "            print(f\"{indent}{key}\")\n",
        "            for subkey, subtree in value.items():\n",
        "                print(f\"{indent}  ├── {subkey}:\")\n",
        "                print_tree(subtree, indent + \"    \")\n",
        "    else:\n",
        "        print(f\"{indent}  └── {tree}\")\n",
        "\n",
        "# Load dataset and run ID3\n",
        "def main():\n",
        "    df = pd.read_csv('/content/id3.csv')\n",
        "    features = list(df.columns[:-1])\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "\n",
        "    # Compute and print information gain for the root node\n",
        "    gains = [information_gain(X, y, i) for i in range(len(features))]\n",
        "    print(\"Information Gain of Root Node:\")\n",
        "    for feature, gain in zip(features, gains):\n",
        "        print(f\"{feature}: {gain:.4f}\")\n",
        "\n",
        "    # Build and print decision tree\n",
        "    tree = id3(X, y, features)\n",
        "    print(\"\\nDecision Tree:\")\n",
        "    print_tree(tree)\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUBnLrY9Q8B7",
        "outputId": "0317aba3-4e1e-4e68-8a98-33a5068b8e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain of Root Node:\n",
            "Outlook: 0.2467\n",
            "Temperature: 0.0292\n",
            "Humidity: 0.1518\n",
            "Wind: 0.0481\n",
            "\n",
            "Decision Tree:\n",
            "Outlook\n",
            "  ├── overcast:\n",
            "      └── yes\n",
            "  ├── rain:\n",
            "    Humidity\n",
            "      ├── cool:\n",
            "        Temperature\n",
            "          ├── rain:\n",
            "            Wind\n",
            "              ├── rain:\n",
            "                  └── yes\n",
            "      ├── mild:\n",
            "        Temperature\n",
            "          ├── rain:\n",
            "            Wind\n",
            "              ├── rain:\n",
            "                  └── yes\n",
            "  ├── sunny:\n",
            "    Wind\n",
            "      ├── high:\n",
            "          └── no\n",
            "      ├── normal:\n",
            "          └── yes\n"
          ]
        }
      ]
    }
  ]
}